{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(len(digits.data))\n",
    "print(digits.target.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "wine = fetch_openml(name='wine', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "print(len(wine.data))\n",
    "print(wine.target.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation for digits dataset\n",
    "\n",
    "digitsTrainingSetSize = int(np.ceil(0.8 * len(digits.data)))\n",
    "digitsValidationSetSize = int(len(digits.data) - digitsTrainingSetSize)\n",
    "\n",
    "xDigitsTrainingSets = []\n",
    "yDigitsTrainingSets = []\n",
    "xDigitsValidationSets = []\n",
    "yDigitsValidationSets = []\n",
    "\n",
    "for foldIndex in range(5):\n",
    "\n",
    "    xValidationSet = []\n",
    "    yValidationSet = []\n",
    "\n",
    "    for index, data in enumerate(digits.data[foldIndex*digitsValidationSetSize:((foldIndex*digitsValidationSetSize)+digitsValidationSetSize)]):\n",
    "        xValidationSet.append(data.tolist())\n",
    "        yValidationSet.append(digits.target[index])\n",
    "    \n",
    "    xTrainingSet = []\n",
    "    yTrainingSet = []\n",
    "\n",
    "    for index, data in enumerate(digits.data.tolist()):\n",
    "        if data not in xValidationSet:\n",
    "            xTrainingSet.append(data)\n",
    "            yTrainingSet.append(digits.target[index])\n",
    "            \n",
    "    xDigitsTrainingSets.append(xTrainingSet)\n",
    "    yDigitsTrainingSets.append(yTrainingSet)\n",
    "    xDigitsValidationSets.append(xValidationSet)\n",
    "    yDigitsValidationSets.append(yValidationSet)\n",
    "    \n",
    "# 5-fold cross validation for wine dataset\n",
    "\n",
    "wineTrainingSetSize = int(np.ceil(0.8 * len(wine.data)))\n",
    "wineValidationSetSize = int(len(wine.data) - wineTrainingSetSize)\n",
    "\n",
    "xWineTrainingSets = []\n",
    "yWineTrainingSets = []\n",
    "xWineValidationSets = []\n",
    "yWineValidationSets = []\n",
    "\n",
    "for foldIndex in range(5):\n",
    "\n",
    "    xValidationSet = []\n",
    "    yValidationSet = []\n",
    "\n",
    "    for index, data in enumerate(wine.data[foldIndex*wineValidationSetSize:((foldIndex*wineValidationSetSize)+wineValidationSetSize)]):\n",
    "        xValidationSet.append(data.tolist())\n",
    "        yValidationSet.append(wine.target[index])\n",
    "    \n",
    "    xTrainingSet = []\n",
    "    yTrainingSet = []\n",
    "\n",
    "    for index, data in enumerate(wine.data.tolist()):\n",
    "        if data not in xValidationSet:\n",
    "            xTrainingSet.append(data)\n",
    "            yTrainingSet.append(wine.target[index])\n",
    "            \n",
    "    xWineTrainingSets.append(xTrainingSet)\n",
    "    yWineTrainingSets.append(yTrainingSet)\n",
    "    xWineValidationSets.append(xValidationSet)\n",
    "    yWineValidationSets.append(yValidationSet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of y for digits dataset\n",
    "\n",
    "numberOfDigitsTargets = 10\n",
    "numberOfWineTargets = 3\n",
    "\n",
    "for index, fold in enumerate(yDigitsTrainingSets):\n",
    "    encodedFold = []\n",
    "    for i, y in enumerate(fold):\n",
    "        encoding = np.zeros(numberOfDigitsTargets)\n",
    "        encoding[y] = 1\n",
    "        encodedFold.append(encoding.tolist())\n",
    "    yDigitsTrainingSets[index] = encodedFold\n",
    "    \n",
    "for index, fold in enumerate(yDigitsValidationSets):\n",
    "    encodedFold = []\n",
    "    for i, y in enumerate(fold):\n",
    "        encoding = np.zeros(numberOfDigitsTargets)\n",
    "        encoding[y] = 1\n",
    "        encodedFold.append(encoding.tolist())\n",
    "    yDigitsValidationSets[index] = encodedFold\n",
    "\n",
    "# one-hot encoding of y for wine dataset\n",
    "\n",
    "for index, fold in enumerate(yWineTrainingSets):\n",
    "    encodedFold = []\n",
    "    for i, y in enumerate(fold):\n",
    "        encoding = np.zeros(numberOfWineTargets)\n",
    "        encoding[int(y)-1] = 1\n",
    "        encodedFold.append(encoding.tolist())\n",
    "    yWineTrainingSets[index] = encodedFold\n",
    "    \n",
    "for index, fold in enumerate(yWineValidationSets):\n",
    "    encodedFold = []\n",
    "    for i, y in enumerate(fold):\n",
    "        encoding = np.zeros(numberOfWineTargets)\n",
    "        encoding[int(y)-1] = 1\n",
    "        encodedFold.append(encoding.tolist())\n",
    "    yWineValidationSets[index] = encodedFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomIndices(arr, batch_size):\n",
    "    indices = []\n",
    "    \n",
    "    if batch_size > len(arr):\n",
    "        print(\"Error: batch size larger than size of dataset.\")\n",
    "        return\n",
    "    \n",
    "    while batch_size > 0:\n",
    "        x = np.floor(np.random.random() * len(arr))\n",
    "        if x not in indices:\n",
    "            indices.append(int(x))\n",
    "            batch_size -= 1\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent class\n",
    " \n",
    "class GradientDescent:\n",
    "    \n",
    "    def __init__(self, batch_size, learning_rate=.001, momentum=0.9, max_iters=10, epsilon=1e-8):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iters = max_iters\n",
    "        self.epsilon = epsilon\n",
    "            \n",
    "    def run(self, gradient_fn, x, y, w):\n",
    "        # TODO: grad variable and usage in loop?\n",
    "        \n",
    "        grad = np.inf\n",
    "        t = 1\n",
    "        \n",
    "        while np.linalg.norm(grad) > self.epsilon and t < self.max_iters:\n",
    "            gradients = gradient_fn(x, y, w, self.batch_size)\n",
    "            \n",
    "            for c in range(len(y[0])):\n",
    "                w[c] = w[c] - self.learning_rate * gradients[c]\n",
    "                print(\"w: \", w[c])\n",
    "                \n",
    "            t += 1\n",
    "        \n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, add_bias=True):\n",
    "        self.add_bias = add_bias\n",
    "        pass\n",
    "            \n",
    "    def fit(self, x, y, optimizer):\n",
    "        # TODO: add bias\n",
    "        \n",
    "        def gradient(x, y, w, batch_size):\n",
    "            gradients = np.zeros(len(w)).tolist()\n",
    "\n",
    "            indices = getRandomIndices(x, batch_size)\n",
    "            print(indices)\n",
    "\n",
    "            for index in indices:\n",
    "                a = np.asarray(x[index])\n",
    "                b = np.asarray(y[index])\n",
    "\n",
    "                for c in range(len(b)):\n",
    "                    w_x =  w[c] @ a\n",
    "                    num = np.exp(w_x)\n",
    "\n",
    "                    den = 0\n",
    "                    for i in range(len(b)):\n",
    "                        w_x =  w[i] @ a\n",
    "                        den += np.exp(w_x)\n",
    "\n",
    "                    yh_c = num/den\n",
    "\n",
    "                    y_c = b[c]\n",
    "                    cost_c = np.dot(yh_c - y_c, a)\n",
    "                    \n",
    "                    if cost_c[0] == 0:\n",
    "                        print(\"x\", a)\n",
    "                        print(\"y\", b)\n",
    "                        print(c)\n",
    "                        print(num)\n",
    "                        print(den)\n",
    "                        print(yh_c)\n",
    "                        print(y_c)\n",
    "                        print(\"gradient\", cost_c)\n",
    "                    \n",
    "\n",
    "                    gradients[c] += cost_c\n",
    "\n",
    "            return gradients\n",
    "        \n",
    "        w0 = []\n",
    "        for c in range(len(y[0])):\n",
    "            w0.append(np.zeros(len(x[0])))\n",
    "            \n",
    "        self.w = optimizer.run(gradient, x, y, w0)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.add_bias:\n",
    "            x = np.column_stack([x,np.ones(N)])\n",
    "        yh = x@self.w\n",
    "        return yh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientDescentModel = GradientDescent(5)\n",
    "logisticRegressionModel = LogisticRegression(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 88, 50, 92, 53]\n",
      "w:  [-2.05400000e-02 -4.16333333e-03 -3.93666667e-03 -3.62000000e-02\n",
      " -1.74333333e-01 -3.80000000e-03 -3.59666667e-03 -6.60000000e-04\n",
      " -3.28666667e-03 -4.54000000e-03 -1.69666667e-03 -4.69333333e-03\n",
      " -9.71000000e-01]\n",
      "w:  [4.10800000e-02 8.32666667e-03 7.87333333e-03 7.24000000e-02\n",
      " 3.48666667e-01 7.60000000e-03 7.19333333e-03 1.32000000e-03\n",
      " 6.57333333e-03 9.08000000e-03 3.39333333e-03 9.38666667e-03\n",
      " 1.94200000e+00]\n",
      "w:  [-2.05400000e-02 -4.16333333e-03 -3.93666667e-03 -3.62000000e-02\n",
      " -1.74333333e-01 -3.80000000e-03 -3.59666667e-03 -6.60000000e-04\n",
      " -3.28666667e-03 -4.54000000e-03 -1.69666667e-03 -4.69333333e-03\n",
      " -9.71000000e-01]\n",
      "[22, 4, 56, 84, 87]\n",
      "x [1.329e+01 1.970e+00 2.680e+00 1.680e+01 1.020e+02 3.000e+00 3.230e+00\n",
      " 3.100e-01 1.660e+00 6.000e+00 1.070e+00 2.840e+00 1.270e+03]\n",
      "y [1. 0. 0.]\n",
      "2\n",
      "0.0\n",
      "inf\n",
      "0.0\n",
      "0.0\n",
      "gradient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "x [1.422e+01 3.990e+00 2.510e+00 1.320e+01 1.280e+02 3.000e+00 3.040e+00\n",
      " 2.000e-01 2.080e+00 5.100e+00 8.900e-01 3.530e+00 7.600e+02]\n",
      "y [1. 0. 0.]\n",
      "2\n",
      "0.0\n",
      "inf\n",
      "0.0\n",
      "0.0\n",
      "gradient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "x [ 12.     1.51   2.42  22.    86.     1.45   1.25   0.5    1.63   3.6\n",
      "   1.05   2.65 450.  ]\n",
      "y [0. 1. 0.]\n",
      "0\n",
      "1.753558852940676e-197\n",
      "inf\n",
      "0.0\n",
      "0.0\n",
      "gradient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "x [ 12.     1.51   2.42  22.    86.     1.45   1.25   0.5    1.63   3.6\n",
      "   1.05   2.65 450.  ]\n",
      "y [0. 1. 0.]\n",
      "2\n",
      "1.753558852940676e-197\n",
      "inf\n",
      "0.0\n",
      "0.0\n",
      "gradient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "x [1.20e+01 3.43e+00 2.00e+00 1.90e+01 8.70e+01 2.00e+00 1.64e+00 3.70e-01\n",
      " 1.87e+00 1.28e+00 9.30e-01 3.05e+00 5.64e+02]\n",
      "y [0. 1. 0.]\n",
      "0\n",
      "1.3830921074444738e-245\n",
      "inf\n",
      "0.0\n",
      "0.0\n",
      "gradient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "x [1.20e+01 3.43e+00 2.00e+00 1.90e+01 8.70e+01 2.00e+00 1.64e+00 3.70e-01\n",
      " 1.87e+00 1.28e+00 9.30e-01 3.05e+00 5.64e+02]\n",
      "y [0. 1. 0.]\n",
      "2\n",
      "1.3830921074444738e-245\n",
      "inf\n",
      "0.0\n",
      "0.0\n",
      "gradient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "x [ 12.42   4.43   2.73  26.5  102.     2.2    2.13   0.43   1.71   2.08\n",
      "   0.92   3.12 365.  ]\n",
      "y [0. 1. 0.]\n",
      "0\n",
      "6.253869911860458e-163\n",
      "inf\n",
      "0.0\n",
      "0.0\n",
      "gradient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "x [ 12.42   4.43   2.73  26.5  102.     2.2    2.13   0.43   1.71   2.08\n",
      "   0.92   3.12 365.  ]\n",
      "y [0. 1. 0.]\n",
      "2\n",
      "6.253869911860458e-163\n",
      "inf\n",
      "0.0\n",
      "0.0\n",
      "gradient [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "w:  [ 6.97000000e-03  1.79666667e-03  1.25333333e-03 -6.20000000e-03\n",
      "  5.56666667e-02  2.20000000e-03  2.67333333e-03 -1.50000000e-04\n",
      "  4.53333333e-04  6.56000000e-03  2.63333333e-04  1.67666667e-03\n",
      "  1.05900000e+00]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [-2.05400000e-02 -4.16333333e-03 -3.93666667e-03 -3.62000000e-02\n",
      " -1.74333333e-01 -3.80000000e-03 -3.59666667e-03 -6.60000000e-04\n",
      " -3.28666667e-03 -4.54000000e-03 -1.69666667e-03 -4.69333333e-03\n",
      " -9.71000000e-01]\n",
      "[31, 26, 87, 52, 118]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "[12, 98, 74, 19, 69]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "[70, 87, 19, 20, 64]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "[38, 51, 58, 79, 71]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "[46, 66, 84, 106, 35]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "[23, 100, 117, 38, 50]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "[62, 61, 15, 115, 6]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "w:  [nan nan nan nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-1ba5324c8e47>:28: RuntimeWarning: overflow encountered in exp\n",
      "  den += np.exp(w_x)\n",
      "<ipython-input-10-1ba5324c8e47>:23: RuntimeWarning: overflow encountered in exp\n",
      "  num = np.exp(w_x)\n",
      "<ipython-input-10-1ba5324c8e47>:30: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  yh_c = num/den\n"
     ]
    }
   ],
   "source": [
    "logisticRegressionModel.fit(xWineTrainingSets[0], yWineTrainingSets[0], gradientDescentModel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#xWineTrainingSets = []\n",
    "#yWineTrainingSets = []\n",
    "#xWineValidationSets = []\n",
    "#yWineValidationSets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
