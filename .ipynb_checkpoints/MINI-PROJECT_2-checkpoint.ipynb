{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(len(digits.data))\n",
    "print(digits.target.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "wine = fetch_openml(name='wine', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "print(len(wine.data))\n",
    "print(wine.target.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation for digits dataset\n",
    "\n",
    "digitsTrainingSetSize = int(np.ceil(0.8 * len(digits.data)))\n",
    "digitsValidationSetSize = int(len(digits.data) - digitsTrainingSetSize)\n",
    "\n",
    "xDigitsTrainingSets = []\n",
    "yDigitsTrainingSets = []\n",
    "xDigitsValidationSets = []\n",
    "yDigitsValidationSets = []\n",
    "\n",
    "for foldIndex in range(5):\n",
    "\n",
    "    xValidationSet = []\n",
    "    yValidationSet = []\n",
    "\n",
    "    for index, data in enumerate(digits.data[foldIndex*digitsValidationSetSize:((foldIndex*digitsValidationSetSize)+digitsValidationSetSize)]):\n",
    "        xValidationSet.append(data.tolist())\n",
    "        yValidationSet.append(digits.target[index])\n",
    "    \n",
    "    xTrainingSet = []\n",
    "    yTrainingSet = []\n",
    "\n",
    "    for index, data in enumerate(digits.data.tolist()):\n",
    "        if data not in xValidationSet:\n",
    "            xTrainingSet.append(data)\n",
    "            yTrainingSet.append(digits.target[index])\n",
    "            \n",
    "    xDigitsTrainingSets.append(xTrainingSet)\n",
    "    yDigitsTrainingSets.append(yTrainingSet)\n",
    "    xDigitsValidationSets.append(xValidationSet)\n",
    "    yDigitsValidationSets.append(yValidationSet)\n",
    "    \n",
    "# 5-fold cross validation for wine dataset\n",
    "\n",
    "wineTrainingSetSize = int(np.ceil(0.8 * len(wine.data)))\n",
    "wineValidationSetSize = int(len(wine.data) - wineTrainingSetSize)\n",
    "\n",
    "xWineTrainingSets = []\n",
    "yWineTrainingSets = []\n",
    "xWineValidationSets = []\n",
    "yWineValidationSets = []\n",
    "\n",
    "for foldIndex in range(5):\n",
    "\n",
    "    xValidationSet = []\n",
    "    yValidationSet = []\n",
    "\n",
    "    for index, data in enumerate(wine.data[foldIndex*wineValidationSetSize:((foldIndex*wineValidationSetSize)+wineValidationSetSize)]):\n",
    "        xValidationSet.append(data.tolist())\n",
    "        yValidationSet.append(wine.target[index])\n",
    "    \n",
    "    xTrainingSet = []\n",
    "    yTrainingSet = []\n",
    "\n",
    "    for index, data in enumerate(wine.data.tolist()):\n",
    "        if data not in xValidationSet:\n",
    "            xTrainingSet.append(data)\n",
    "            yTrainingSet.append(wine.target[index])\n",
    "            \n",
    "    xWineTrainingSets.append(xTrainingSet)\n",
    "    yWineTrainingSets.append(yTrainingSet)\n",
    "    xWineValidationSets.append(xValidationSet)\n",
    "    yWineValidationSets.append(yValidationSet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of y for digits dataset\n",
    "\n",
    "numberOfDigitsTargets = 10\n",
    "numberOfWineTargets = 3\n",
    "\n",
    "for fold in yDigitsTrainingSets:\n",
    "    encodedFold = []\n",
    "    for index, y in enumerate(fold):\n",
    "        encoding = np.zeros(numberOfDigitsTargets)\n",
    "        encoding[y] = 1\n",
    "        encodedFold.append(encoding)\n",
    "    fold = encodedFold\n",
    "    \n",
    "for fold in yDigitsValidationSets:\n",
    "    encodedFold = []\n",
    "    for index, y in enumerate(fold):\n",
    "        encoding = np.zeros(numberOfDigitsTargets)\n",
    "        encoding[y] = 1\n",
    "        encodedFold.append(encoding)\n",
    "    fold = encodedFold\n",
    "\n",
    "# one-hot encoding of y for wine dataset\n",
    "\n",
    "for fold in yWineTrainingSets:\n",
    "    encodedFold = []\n",
    "    for index, y in enumerate(fold):\n",
    "        encoding = np.zeros(numberOfWineTargets)\n",
    "        encoding[int(y)-1] = 1\n",
    "        encodedFold.append(encoding)\n",
    "    fold = encodedFold\n",
    "    \n",
    "for fold in yWineValidationSets:\n",
    "    encodedFold = []\n",
    "    for index, y in enumerate(fold):\n",
    "        encoding = np.zeros(numberOfWineTargets)\n",
    "        encoding[int(y)-1] = 1\n",
    "        encodedFold.append(encoding)\n",
    "    fold = encodedFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray([[1, 1, 1, 1], [2,2,2,2]])\n",
    "y = np.asarray([10, 20])\n",
    "w = np.asarray([[1, 2, 3, 4], [4, 2, 3, 4]])\n",
    "\n",
    "def getRandom(arr, batch_size):\n",
    "    indices = []\n",
    "    taken = []\n",
    "    print(arr)\n",
    "    \n",
    "    if batch_size > len(arr):\n",
    "        print(\"Error: batch size larger than size of dataset.\")\n",
    "        return\n",
    "    \n",
    "    while batch_size >= 0:\n",
    "        x = np.floor(np.random.random() * len(arr))\n",
    "\n",
    "getRandom(x[0], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "getRandom(x[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, y, w, batch_size):\n",
    "    # return 3 gradients, one for each class\n",
    "    \n",
    "    gradients = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for c in range(y.size):\n",
    "        wx =  w[c] @ x\n",
    "        num = np.exp(wx)\n",
    "        \n",
    "        den = 0\n",
    "        for c in range(y.size):\n",
    "            wx =  w[c] @ x\n",
    "            den += np.exp(wx)\n",
    "        \n",
    "        yhc = num/den\n",
    "        softmax_x.append(yhc)\n",
    "    \n",
    "    print(softmax_x)\n",
    "    \n",
    "        \n",
    "print(gradient(x, y, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent class\n",
    "\n",
    "class GradientDescent:\n",
    "    \n",
    "    def __init__(self, learning_rate=.001, momentum=0.9, batch_size, max_iters=1e4, epsilon=1e-8, record_history=False):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iters = max_iters\n",
    "        self.record_history = record_history\n",
    "        self.epsilon = epsilon\n",
    "        if record_history:\n",
    "            self.w_history = []\n",
    "            \n",
    "    def run(self, x, y, w):\n",
    "        # x = [x1, x2, ..., xn]\n",
    "        # y = [y1 = [c1, c2, c3], y2 = [c1, c2, c3], ..., yn]\n",
    "        # w = [w1 = [c1 = [x1, x2,...], c2 = [x1, x2,...], ...], ...]\n",
    "        \n",
    "        grad = np.inf\n",
    "        t = 1\n",
    "        def gradient(x, y, w):\n",
    "            yh =  x @ w \n",
    "            N, D = x.shape\n",
    "            grad = .5*np.dot(yh - y, x)/N\n",
    "            return grad\n",
    "        while np.linalg.norm(grad) > self.epsilon and t < self.max_iters:\n",
    "            grad = gradient(x, y, w)\n",
    "            w = w - self.learning_rate * grad\n",
    "            if self.record_history:\n",
    "                self.w_history.append(w)\n",
    "            t += 1\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change linear regression to logistic regression\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, add_bias=True):\n",
    "        self.add_bias = add_bias\n",
    "        pass\n",
    "            \n",
    "    def fit(self, x, y, optimizer):\n",
    "        if x.ndim == 1:\n",
    "            x = x[:, None]\n",
    "        if self.add_bias:\n",
    "            N = x.shape[0]\n",
    "            x = np.column_stack([x,np.ones(N)])\n",
    "        N,D = x.shape\n",
    "        def gradient(x, y, w):\n",
    "            yh =  x @ w \n",
    "            N, D = x.shape\n",
    "            grad = .5*np.dot(yh - y, x)/N\n",
    "            return grad\n",
    "        w0 = np.zeros(D)\n",
    "        self.w = optimizer.run(gradient, x, y, w0)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.add_bias:\n",
    "            x = np.column_stack([x,np.ones(N)])\n",
    "        yh = x@self.w\n",
    "        return yh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fn(x, y, w):\n",
    "    N, D = x.shape                                                       \n",
    "    z = np.dot(x, w)\n",
    "    J = np.mean(y * np.log1p(np.exp(-z)) + (1-y) * np.log1p(np.exp(z)))  #log1p calculates log(1+x) to remove floating point inaccuracies \n",
    "    return J"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
